{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Adding Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd # used to load, manipulate the data and for one-hot encoding\nimport numpy as np # data manipulation\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as colors\nfrom sklearn.utils import resample # for downsample the dataset\nfrom sklearn.model_selection import train_test_split # for splitting the dataset into train and test split\nfrom sklearn.preprocessing import scale # scale and center the data\nfrom sklearn.svm import SVC # will make a SVM for classification\nfrom sklearn.model_selection import GridSearchCV # will do the cross validation\nfrom sklearn.metrics import plot_confusion_matrix # will draw the confusion matrix\nfrom sklearn.decomposition import PCA # to perform PCA to plot the data\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix, precision_score, accuracy_score, recall_score, roc_curve, auc\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load the data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/mri-and-alzheimers/oasis_longitudinal.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Explore the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', None) # will show the all columns with pandas dataframe\npd.set_option('display.max_rows', None) # will show the all rows with pandas dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()\n# data.tail()\n# data.size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Converting Categorical Data to Numerical Data"},{"metadata":{},"cell_type":"markdown","source":"When **inplace = True** , the data is modified in place, which means it will return nothing and the dataframe is now updated. \nWhen **inplace = False** , which is the *default*, then the operation is performed and it returns a copy of the object. You then need to save it to something."},{"metadata":{},"cell_type":"markdown","source":"set axis=0 for rows or, just put axis='rows' to access the rows\n\nset axis=1 for columns or, just put axis='columns' to access the columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['M/F'] = [1 if each == \"M\" else 0 for each in data['M/F']]\ndata['Group'] = [1 if each == \"Demented\" or each == \"Converted\" else 0 for each in data['Group']]\n# data['Group'] = data['Group'].replace(['Converted'], ['Demented']) # Target variable\n# data['Group'] = data['Group'].replace(['Demented', 'Nondemented'], [1,0]) # Target variable\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: Based on the given data **CDR** is used to tell what the condition of the patient meaning, does the patient has any dementia or, not.\n\nCDR Value Meaning:\n\n* 0 ---> Normal\n* 0.5 ---> Very Mild Dementia\n* 1 ---> Mild Dementia\n* 2 ---> Moderate Dementia\n* 3 ---> Severe Dementia"},{"metadata":{},"cell_type":"markdown","source":"## Correlation Between Attributes"},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation_matrix = data.corr()\ndata_corr = correlation_matrix['Group'].sort_values(ascending=False)\ndata_corr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.plotting import scatter_matrix\n\nattributes = [\"Group\", \"CDR\", \"M/F\", \"SES\", \"ASF\"]\n\nscatter_matrix(data[attributes], figsize=(15, 11), alpha=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\nfig = px.scatter(data, x='Group', y='SES', color='Group')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\nfig = px.scatter(data, x='Group', y='Age', color='Group')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\nfig = px.scatter(data, x='Group', y='ASF', color='Group')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking For Missig/Null Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Taking median values for the missing values of MMSE"},{"metadata":{"trusted":true},"cell_type":"code","source":"median = data['MMSE'].median()\ndata['MMSE'].fillna(median, inplace=True)\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Taking median values for the missing values of SES"},{"metadata":{"trusted":true},"cell_type":"code","source":"median = data['SES'].median()\ndata['SES'].fillna(median, inplace=True)\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train-Test Split"},{"metadata":{},"cell_type":"markdown","source":"## Prepare the data for X and y where, \n\n1. X = The columns/features for **making the prediction**\n2. y = The **predicted value**"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data['Group'].values\nX = data[['M/F', 'Age', 'EDUC', 'SES', 'MMSE', 'eTIV', 'nWBV', 'ASF']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train-Test distribution Without Stratified Sampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# by default test_size= 0.25\nX_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size= 0.20, random_state=42)\n\ndf_ytrain = pd.DataFrame(y_trainval)\ndf_ytest = pd.DataFrame(y_test)\n\nprint('In Training Split:')\nprint(df_ytrain[0].value_counts())\n\nprint('\\nIn Testing Split:')\nprint(df_ytest[0].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### With Stratified Sampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# by default test_size= 0.25\nX_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size= 0.20, random_state=42, stratify=y)\n\n\ndf_ytrain = pd.DataFrame(y_trainval)\ndf_ytest = pd.DataFrame(y_test)\n\nprint('In Training Split:')\nprint(df_ytrain[0].value_counts())\n\nprint('\\nIn Testing Split:')\nprint(df_ytest[0].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scale the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# here StandardScaler() means z = (x - u) / s\nscaler = StandardScaler().fit(X_trainval)\n#scaler = MinMaxScaler().fit(X_trainval)\nX_trainval_scaled = scaler.transform(X_trainval)\nX_test_scaled = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_trainval_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_trainval.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_trainval.hist(bins=30, figsize=(20,15))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\nx = ['M/F', 'Age', 'EDUC', 'SES', 'MMSE', 'eTIV', 'nWBV', 'ASF']\n\nfig = px.histogram(X_trainval, x='eTIV', nbins=50)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\nx = ['M/F', 'Age', 'EDUC', 'SES', 'MMSE', 'eTIV', 'nWBV', 'ASF']\n\nfig = px.scatter(X_trainval, x='eTIV')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_svm = SVC(random_state=42)\nclf_svm.fit(X_trainval_scaled, y_trainval)\n\n# for test there are 94 cases\nplot_confusion_matrix(clf_svm, \n                      X_test_scaled, \n                      y_test, \n                      values_format='d', \n                      display_labels=['Nondemented', 'Demented'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_score = 0\ntest_score = 0\ntest_recall = 0\ntest_auc = 0\n\ntrain_score = clf_svm.score(X_trainval_scaled, y_trainval)\ntest_score = clf_svm.score(X_test_scaled, y_test)\ny_predict = clf_svm.predict(X_test_scaled)\n\ntest_recall = recall_score(y_test, y_predict)\nfpr, tpr, thresholds = roc_curve(y_test, y_predict)\ntest_auc = auc(fpr, tpr)\n\n\nprint(\"Train accuracy \", train_score)\nprint(\"Test accuracy \", test_score)\nprint(\"Test recall\", test_recall)\nprint(\"Test AUC\", test_auc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Optimize parameters(Finetuning) --> GridSearchCV() for SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normally, C = 1 and gamma = 'scale' are default values\n# C controls how wide the margin will be with respect to how many misclassification we are allowing\n# C is increasing --> reduce the size of the margin and fewer misclassification and vice versa\nparam_grid = [\n    {'C': [0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 30, 50, 80, 100],\n    'gamma': ['scale', 0.5, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001],\n    'kernel': ['rbf', 'linear', 'poly', 'sigmoid']},\n]\n\noptimal_params = GridSearchCV(SVC(),\n                             param_grid,\n                             cv=5, # we are taking 5-fold as in k-fold cross validation\n                             scoring='accuracy', # try the other scoring if have time\n                             verbose=0,\n                             n_jobs=-1)\n\noptimal_params.fit(X_trainval_scaled, y_trainval)\nprint(optimal_params.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"C = optimal_params.best_params_['C']\ngamma = optimal_params.best_params_['gamma']\nkernel = optimal_params.best_params_['kernel']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_svm = SVC(random_state=42, C=C, gamma=gamma, kernel=kernel)\nclf_svm.fit(X_trainval_scaled, y_trainval)\n\nplot_confusion_matrix(clf_svm, \n                      X_test_scaled, \n                      y_test, \n                      values_format='d', \n                      display_labels=['Nondemented', 'Demented'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_score = 0\ntest_score = 0\ntest_recall = 0\ntest_auc = 0\n\ntrain_score = clf_svm.score(X_trainval_scaled, y_trainval)\ntest_score = clf_svm.score(X_test_scaled, y_test)\ny_predict = clf_svm.predict(X_test_scaled)\n\ntest_recall = recall_score(y_test, y_predict)\nsvm_fpr, svm_tpr, thresholds = roc_curve(y_test, y_predict)\ntest_auc = auc(svm_fpr, svm_tpr)\n\n\nprint(\"Train accuracy \", train_score)\nprint(\"Test accuracy \", test_score)\nprint(\"Test recall\", test_recall)\nprint(\"Test AUC\", test_auc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# n_estimators(M) --> the number of trees in the forest\n# max_features(d) --> the number of features to consider when looking for the best split\n# max_depth(m) --> the maximum depth of the tree.\n\nrfc = RandomForestClassifier(random_state=42)\nrfc.fit(X_trainval_scaled, y_trainval)\n\n# for test there are 94 cases\nplot_confusion_matrix(rfc, \n                      X_test_scaled, \n                      y_test, \n                      values_format='d', \n                      display_labels=['Nondemented', 'Demented'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_score = 0\ntest_score = 0\ntest_recall = 0\ntest_auc = 0\n\ntrain_score = rfc.score(X_trainval_scaled, y_trainval)\ntest_score = rfc.score(X_test_scaled, y_test)\ny_predict = rfc.predict(X_test_scaled)\ntest_recall = recall_score(y_test, y_predict)\nfpr, tpr, thresholds = roc_curve(y_test, y_predict)\ntest_auc = auc(fpr, tpr)\n\nprint(\"Train accuracy \", train_score)\nprint(\"Test accuracy \", test_score)\nprint(\"Test recall\", test_recall)\nprint(\"Test AUC\", test_auc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Optimize parameters(Finetuning) --> GridSearchCV()"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt', 'log2']\n\n# Maximum number of levels in tree\nmax_depth = range(1,10)\n\n# measure the quality of a split\ncriterion = ['gini']\n\n# Method of selecting samples for training each tree\nbootstrap = [True, False]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the param grid\nparam_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'criterion': criterion,\n               'bootstrap': bootstrap}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimal_params = GridSearchCV(RandomForestClassifier(),\n                             param_grid,\n                             cv=5, # we are taking 5-fold as in k-fold cross validation\n                             scoring='accuracy', # try the other scoring if have time\n                             verbose=0,\n                             n_jobs=-1)\n\noptimal_params.fit(X_trainval_scaled, y_trainval)\nprint(optimal_params.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bootstrap = optimal_params.best_params_['bootstrap']\ncriterion = optimal_params.best_params_['criterion']\nmax_depth = optimal_params.best_params_['max_depth']\nmax_features = optimal_params.best_params_['max_features']\nn_estimators = optimal_params.best_params_['n_estimators']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=n_estimators, \n                             max_features=max_features, \n                             max_depth=max_depth, \n                             criterion=criterion,\n                             bootstrap=bootstrap,\n                             random_state=42)\n\nrfc.fit(X_trainval_scaled, y_trainval)\n\n# for test there are 94 cases\nplot_confusion_matrix(rfc, \n                      X_test_scaled, \n                      y_test, \n                      values_format='d', \n                      display_labels=['Nondemented', 'Demented'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_score = 0\ntest_score = 0\ntest_recall = 0\ntest_auc = 0\n\ntrain_score = rfc.score(X_trainval_scaled, y_trainval)\ntest_score = rfc.score(X_test_scaled, y_test)\ny_predict = rfc.predict(X_test_scaled)\ntest_recall = recall_score(y_test, y_predict)\nrfc_fpr, rfc_tpr, thresholds = roc_curve(y_test, y_predict)\ntest_auc = auc(rfc_fpr, rfc_tpr)\n\nprint(\"Train accuracy \", train_score)\nprint(\"Test accuracy \", test_score)\nprint(\"Test recall\", test_recall)\nprint(\"Test AUC\", test_auc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix, precision_score, accuracy_score, recall_score, roc_curve, auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg_model = LogisticRegression().fit(X_trainval_scaled, y_trainval)\n\n# for test there are 94 cases\nplot_confusion_matrix(log_reg_model, \n                      X_test_scaled, \n                      y_test, \n                      values_format='d', \n                      display_labels=['Nondemented', 'Demented'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_score = 0\ntest_score = 0\ntest_recall = 0\ntest_auc = 0\n\nlog_reg_model = LogisticRegression().fit(X_trainval_scaled, y_trainval)\ntrain_score = log_reg_model.score(X_trainval_scaled, y_trainval)\ntest_score = log_reg_model.score(X_test_scaled, y_test)\nscores = log_reg_model.score(X_test_scaled, y_test)\ny_predict = log_reg_model.predict(X_test_scaled)\ntest_recall = recall_score(y_test, y_predict)\nfpr, tpr, thresholds = roc_curve(y_test, y_predict)\ntest_auc = auc(fpr, tpr)\n\n\nprint(\"Train accuracy \", train_score)\nprint(\"Test accuracy \", test_score)\nprint(\"Test recall\", test_recall)\nprint(\"Test AUC\", test_auc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Optimize parameters(Finetuning) --> GridSearchCV()"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'penalty': ['l1','l2'], \n               'C': [0.001,0.01,0.1,1, 2, 3, 5, 10,100,1000]}\n\noptimal_params = GridSearchCV(LogisticRegression(),\n                             param_grid,\n                             cv=5, # we are taking 5-fold as in k-fold cross validation\n                             scoring='accuracy', # try the other scoring if have time\n                             verbose=0,\n                             n_jobs=-1)\n\noptimal_params.fit(X_trainval_scaled, y_trainval)\nprint(optimal_params.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best_score = -10\n# for c in range(1, 20):       \n#         log_reg_model = LogisticRegression(C=c)\n#         scores = cross_val_score(log_reg_model, X_trainval_scaled, y_trainval, cv=5, scoring='accuracy')\n        \n#         mean_score = scores.mean()\n        \n#         if mean_score > best_score:\n#             best_score = mean_score\n#             best_c = c\n# print(best_c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_C = optimal_params.best_params_['C']\nbest_penalty = optimal_params.best_params_['penalty']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg_model = LogisticRegression(C=best_C, penalty=best_penalty).fit(X_trainval_scaled, y_trainval)\n\n# for test there are 94 cases\nplot_confusion_matrix(log_reg_model, \n                      X_test_scaled, \n                      y_test, \n                      values_format='d', \n                      display_labels=['Nondemented', 'Demented'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_score = 0\ntest_score = 0\ntest_recall = 0\ntest_auc = 0\n\nbest_log_reg_model = LogisticRegression(C=best_C, penalty=best_penalty).fit(X_trainval_scaled, y_trainval)\ntrain_score = best_log_reg_model.score(X_trainval_scaled, y_trainval)\ntest_score = best_log_reg_model.score(X_test_scaled, y_test)\ny_predict = best_log_reg_model.predict(X_test_scaled)\ntest_recall = recall_score(y_test, y_predict)\nlgr_fpr, lgr_tpr, thresholds = roc_curve(y_test, y_predict)\ntest_auc = auc(lgr_fpr, lgr_tpr)\n\nprint(\"Train accuracy with Logistec regression:\", train_score)\nprint(\"Test accuracy with Logistec regression:\", test_score)\nprint(\"Test recall with Logistec regression:\", test_recall)\nprint(\"Test AUC with Logistec regression:\", test_auc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_model = DecisionTreeClassifier().fit(X_trainval_scaled, y_trainval)\n\n# for test there are 94 cases\nplot_confusion_matrix(dt_model, \n                      X_test_scaled, \n                      y_test, \n                      values_format='d', \n                      display_labels=['Nondemented', 'Demented'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_score = 0\ntest_score = 0\ntest_recall = 0\ntest_auc = 0\n\ndt_model = DecisionTreeClassifier().fit(X_trainval_scaled, y_trainval)\ntrain_score = dt_model.score(X_trainval_scaled, y_trainval)\ntest_score = dt_model.score(X_test_scaled, y_test)\ny_predict = dt_model.predict(X_test_scaled)\ntest_recall = recall_score(y_test, y_predict)\nfpr, tpr, thresholds = roc_curve(y_test, y_predict)\ntest_auc = auc(fpr, tpr)\n\nprint(\"Train accuracy with DecisionTreeClassifier:\", train_score)\nprint(\"Test accuracy with DecisionTreeClassifier:\", test_score)\nprint(\"Test recall with DecisionTreeClassifier:\", test_recall)\nprint(\"Test AUC with DecisionTreeClassifier:\", test_auc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Optimize parameters(Finetuning) --> GridSearchCV()"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'criterion': ['gini'], \n              'max_depth': range(1,10)}\n\noptimal_params = GridSearchCV(DecisionTreeClassifier(),\n                             param_grid,\n                             cv=5, # we are taking 5-fold as in k-fold cross validation\n                             scoring='accuracy', # try the other scoring if have time\n                             verbose=0,\n                             n_jobs=-1)\n\noptimal_params.fit(X_trainval_scaled, y_trainval)\nprint(optimal_params.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = optimal_params.best_params_['criterion']\nmax_depth = optimal_params.best_params_['max_depth']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best_score = -1\n# for d in range(1, 25):       \n#         dt_model = DecisionTreeClassifier(max_depth = d)\n#         scores = cross_val_score(dt_model, X_trainval_scaled, y_trainval, cv=5, scoring='accuracy')\n        \n#         mean_score = scores.mean()\n        \n#         if mean_score > best_score:\n#             best_score = mean_score\n#             best_d = d\n# print(best_d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_model = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth).fit(X_trainval_scaled, y_trainval)\n\n# for test there are 94 cases\nplot_confusion_matrix(dt_model, \n                      X_test_scaled, \n                      y_test, \n                      values_format='d', \n                      display_labels=['Nondemented', 'Demented'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_score = 0\ntest_score = 0\ntest_recall = 0\ntest_auc = 0\n\ndt_model = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth).fit(X_trainval_scaled, y_trainval)\ntrain_score = dt_model.score(X_trainval_scaled, y_trainval)\ntest_score = dt_model.score(X_test_scaled, y_test)\ny_predict = dt_model.predict(X_test_scaled)\ntest_recall = recall_score(y_test, y_predict)\ndt_fpr, dt_tpr, thresholds = roc_curve(y_test, y_predict)\ntest_auc = auc(dt_fpr, dt_tpr)\n\nprint(\"Train accuracy with DecisionTreeClassifier:\", train_score)\nprint(\"Test accuracy with DecisionTreeClassifier:\", test_score)\nprint(\"Test recall with DecisionTreeClassifier:\", test_recall)\nprint(\"Test AUC with DecisionTreeClassifier:\", test_auc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot ROC and compare AUC"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5, 5), dpi=100)\nplt.plot(svm_fpr, svm_tpr, linestyle='-', label='SVM')\nplt.plot(lgr_fpr, lgr_tpr, marker='.', label='Logistic')\nplt.plot(rfc_fpr, rfc_tpr, linestyle=':', label='Random Forest')\nplt.plot(dt_fpr, dt_tpr, linestyle='-.', label='Decision Tree')\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}